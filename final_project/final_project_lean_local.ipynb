{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final project with all of the experiments stripped out.\n",
    "\n",
    "### load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>4175000</td>\n",
       "      <td>2869717</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>1729541</td>\n",
       "      <td>13868</td>\n",
       "      <td>2195</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>304805</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>126027</td>\n",
       "      <td>-126027</td>\n",
       "      <td>201955</td>\n",
       "      <td>1407</td>\n",
       "      <td>2902</td>\n",
       "      <td>4484442</td>\n",
       "      <td>1729541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182466</td>\n",
       "      <td>257817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>4046157</td>\n",
       "      <td>56301</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864523</td>\n",
       "      <td>False</td>\n",
       "      <td>1757552</td>\n",
       "      <td>-560222</td>\n",
       "      <td>477</td>\n",
       "      <td>465</td>\n",
       "      <td>566</td>\n",
       "      <td>916197</td>\n",
       "      <td>5243487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>400000</td>\n",
       "      <td>260455</td>\n",
       "      <td>-201641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "      <td>145796</td>\n",
       "      <td>-82782</td>\n",
       "      <td>239671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>827696</td>\n",
       "      <td>63014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bonus deferral_payments deferred_income director_fees  \\\n",
       "ALLEN PHILLIP K     4175000           2869717        -3081055           NaN   \n",
       "BADUM JAMES P           NaN            178980             NaN           NaN   \n",
       "BANNANTINE JAMES M      NaN               NaN           -5104           NaN   \n",
       "BAXTER JOHN C       1200000           1295738        -1386055           NaN   \n",
       "BAY FRANKLIN R       400000            260455         -201641           NaN   \n",
       "\n",
       "                                 email_address exercised_stock_options  \\\n",
       "ALLEN PHILLIP K        phillip.allen@enron.com                 1729541   \n",
       "BADUM JAMES P                              NaN                  257817   \n",
       "BANNANTINE JAMES M  james.bannantine@enron.com                 4046157   \n",
       "BAXTER JOHN C                              NaN                 6680544   \n",
       "BAY FRANKLIN R             frank.bay@enron.com                     NaN   \n",
       "\n",
       "                   expenses from_messages from_poi_to_this_person  \\\n",
       "ALLEN PHILLIP K       13868          2195                      47   \n",
       "BADUM JAMES P          3486           NaN                     NaN   \n",
       "BANNANTINE JAMES M    56301            29                      39   \n",
       "BAXTER JOHN C         11200           NaN                     NaN   \n",
       "BAY FRANKLIN R       129142           NaN                     NaN   \n",
       "\n",
       "                   from_this_person_to_poi        ...         \\\n",
       "ALLEN PHILLIP K                         65        ...          \n",
       "BADUM JAMES P                          NaN        ...          \n",
       "BANNANTINE JAMES M                       0        ...          \n",
       "BAXTER JOHN C                          NaN        ...          \n",
       "BAY FRANKLIN R                         NaN        ...          \n",
       "\n",
       "                   long_term_incentive    other    poi restricted_stock  \\\n",
       "ALLEN PHILLIP K                 304805      152  False           126027   \n",
       "BADUM JAMES P                      NaN      NaN  False              NaN   \n",
       "BANNANTINE JAMES M                 NaN   864523  False          1757552   \n",
       "BAXTER JOHN C                  1586055  2660303  False          3942714   \n",
       "BAY FRANKLIN R                     NaN       69  False           145796   \n",
       "\n",
       "                   restricted_stock_deferred  salary shared_receipt_with_poi  \\\n",
       "ALLEN PHILLIP K                      -126027  201955                    1407   \n",
       "BADUM JAMES P                            NaN     NaN                     NaN   \n",
       "BANNANTINE JAMES M                   -560222     477                     465   \n",
       "BAXTER JOHN C                            NaN  267102                     NaN   \n",
       "BAY FRANKLIN R                        -82782  239671                     NaN   \n",
       "\n",
       "                   to_messages total_payments total_stock_value  \n",
       "ALLEN PHILLIP K           2902        4484442           1729541  \n",
       "BADUM JAMES P              NaN         182466            257817  \n",
       "BANNANTINE JAMES M         566         916197           5243487  \n",
       "BAXTER JOHN C              NaN        5634343          10623258  \n",
       "BAY FRANKLIN R             NaN         827696             63014  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Eliminate Outliers/Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "#letting the imputer deal with missing data\n",
    "#df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['deferred_ratio'] = df['deferred_income']/(df['total_payments'] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn prep: features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try a variety of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to try the GridSearchCV tutorial with the data in the machine learning class. \n",
    "\n",
    "From page 1, I start with the data in a pandas data frame. \n",
    "\n",
    "We don't have any categorical variables besides the dependent variable so I will not have to use the sklearn.preprocessing.LabelEncoder() or the pandas.get_dummies() functions. \n",
    "\n",
    "The data is in a pandas data frame and has not been split into training or testing data sets. So what we have to do is create the features and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df[features_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing data has already been dealt with by the Pandas function fillna() with the NaN's set to 0. We will try it again with the missing data imputation strategy set to median but that will come later when we start with the pipeline. Now we create the training/test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model I will try this with is decision trees since that is what they go through in the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score:\n",
      "0.0\n",
      "\n",
      "\n",
      "Precision score:\n",
      "0.0\n",
      "\n",
      "\n",
      "Decision Tree Accuracy score:\n",
      "0.840909090909\n",
      "\n",
      "Decision Tree Parameters:\n",
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 53,\n",
      " 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.preprocessing import Imputer\n",
    "                                                \n",
    "from pprint import pprint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median')\n",
    "features_train = imp.fit_transform(features_train)\n",
    "features_test = imp.fit_transform(features_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state = 53)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "\n",
    "labels_pred = clf.predict(features_test)\n",
    "print \"Recall score:\"\n",
    "print recall_score(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Precision score:\"\n",
    "print precision_score(labels_test, labels_pred)\n",
    "print \"\\n\"\n",
    "\n",
    "print \"Decision Tree Accuracy score:\"\n",
    "print clf.score(features_test, labels_test)\n",
    "\n",
    "print \"\\nDecision Tree Parameters:\"\n",
    "pprint(clf.get_params())\n",
    "\n",
    "\n",
    "# precision_recall_fscore_support(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't believe that we get 0 scores for both precision and recall, so I investigate further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(labels_test)):\n",
    "    if labels_test[i] == 1 and labels_pred[i]:\n",
    "        count += 1\n",
    "        print \"got one!\"\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I still can't believe we get nothing so I try one more test. I print out the test set labels and the predicted values for the labels side by side and visually inspect them. Finally, I am satisfied that the decision tree model gets us absolutely nothing. Its high accuracy score is merely an artifact of the very low number of positives making it possible for a model to achieve fairly high accuracy by simply predicting 0 for person of interest most of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 1.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 1.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 1.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 1.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 1.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 1.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n",
      "True: 0.0 Pred: 1.0\n",
      "\n",
      "True: 0.0 Pred: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels_test)):\n",
    "    print \"True: %r Pred: %r\\n\" %(labels_test[i], labels_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, unless I find some other way to do make a bunch of train-test splits when I run a model I may not be able to get anywhere just running looking for models with high recall on just the single small data set we have here. I am going to try the grid search with the scoring function set to recall but we are going to have to have to think that the recall score might not give us enough to work with. \n",
    "\n",
    "The cross validation parameter of the grid search may save the day. It may, though I am not sure, make some changes in the train-test split somehow, sampling from within the data set, to give us more leverage. I will have to try it out to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation\n",
    "So we make lists of the parameters of the model that we want to search through. Then there are parameters of the GridSearchCV model itself. Then we fit the model, test its predictions and print out the best estimator and its parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from the parameter grid:\n",
      "{'max_depth': 4, 'min_samples_split': 25}\n",
      "\n",
      "Complete set of parameters for best estimator:\n",
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 25,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 53,\n",
      " 'splitter': 'best'}\n",
      "\n",
      "Accuracy score for default decision tree:\n",
      "0.840909090909\n",
      "\n",
      "Accuracy score for the grid search estimator:\n",
      "0.772727272727\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "#create a dictionary with the parameeters we want to search through\n",
    "param_grid = {'min_samples_split': [1, 5, 10, 15, 20, 25, 30],\n",
    "             'max_depth': [4, 5, 6, 7, 8]}\n",
    "\n",
    "#create the grid_search object\n",
    "gridCV_object = grid_search.GridSearchCV(estimator = DecisionTreeClassifier(random_state=53),\n",
    "                                        param_grid = param_grid,\n",
    "                                        cv = 5)\n",
    "\n",
    "#fit to the data\n",
    "gridCV_object.fit(features_train, labels_train)\n",
    "\n",
    "#find the best parameters chosen\n",
    "print \"Best parameters from the parameter grid:\" \n",
    "pprint(gridCV_object.best_params_)\n",
    "\n",
    "#get the best estimator\n",
    "clf_2 = gridCV_object.best_estimator_\n",
    "\n",
    "#get the best parameters from the best estimator\n",
    "print \"\\nComplete set of parameters for best estimator:\"\n",
    "pprint(clf_2.get_params())\n",
    "\n",
    "#compare scores for the default and the grid search decision trees\n",
    "print \"\\nAccuracy score for default decision tree:\"\n",
    "print clf.score(features_test, labels_test)\n",
    "\n",
    "print \"\\nAccuracy score for the grid search estimator:\"\n",
    "print clf_2.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was a big huge drop for the grid search estimator. I have no idea why but it somehow does not seem surprising. Maybe there is something about the grid search and the way it is set up that won't let the thing just guess that no one is a poi? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "labels_pred_2 = clf_2.predict(features_test)\n",
    "print recall_score(labels_test, labels_pred_2) \n",
    "print precision_score(labels_test, labels_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so the decision tree classifier is absolutely terrible but it is at least doing something after grid search as opposed to the tree classifier with just the default parameters which was just flat out zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweeking the Decision Tree: StratifiedShuffleSplit\n",
    "This is a model that, I believe, lets you get a bit more milliage out of the grid search by doing splits of the training data to get more robust tests of the data making up for the small size of the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters chosen from the grid:\n",
      "{'max_depth': 4, 'min_samples_split': 15}\n",
      "Best estimator:\n",
      "The best parameters for the best estimator:\n",
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 15,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 53,\n",
      " 'splitter': 'best'}\n",
      "\n",
      " F1 score for default decision tree:\n",
      "0.0\n",
      "\n",
      "F1 score for best estimator:\n",
      "0.166666666667\n"
     ]
    }
   ],
   "source": [
    "#keep same param_grid for now\n",
    "#create StratefiedShuffleSplit object\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "cross_validator = StratifiedShuffleSplit(y = labels_train, random_state = 0)\n",
    "\n",
    "#create grid_search object\n",
    "gridCV_object = grid_search.GridSearchCV(estimator = DecisionTreeClassifier(random_state=53),\n",
    "                                        param_grid = param_grid,\n",
    "                                        scoring = 'f1',\n",
    "                                        cv = cross_validator)\n",
    "\n",
    "#fit to the data to the new grid search\n",
    "gridCV_object.fit(features_train, labels_train)\n",
    "\n",
    "#what were the parameteres chosen from the grid?\n",
    "print \"Parameters chosen from the grid:\"\n",
    "pprint(gridCV_object.best_params_)\n",
    "\n",
    "#get best estimator\n",
    "print \"Best estimator:\"\n",
    "clf_f1 = gridCV_object.best_estimator_\n",
    "\n",
    "#get the best parameters for the best estimator\n",
    "print \"The best parameters for the best estimator:\"\n",
    "pprint(clf_f1.get_params())\n",
    "\n",
    "#check the scores\n",
    "from sklearn.metrics import f1_score\n",
    "print \"\\n F1 score for default decision tree:\"\n",
    "predictions_1 = clf.predict(features_test)\n",
    "print f1_score(predictions_1, labels_test)\n",
    "\n",
    "#now for the grid search determined parameters:\n",
    "print \"\\nF1 score for best estimator:\"\n",
    "predictions_2 = clf_f1.predict(features_test)\n",
    "print f1_score(predictions_2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "Now I am going to do the whole thing for the recall score, still using the decision tree but using a wider set of parameters and using the stratified shuffle split testing method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters chosen from the grid:\n",
      "{'max_depth': 4, 'min_samples_split': 15}\n",
      "Best estimator:\n",
      "The best parameters for the best estimator:\n",
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 4,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 15,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 53,\n",
      " 'splitter': 'best'}\n",
      "\n",
      "Recall score for default decision tree:\n",
      "0.0\n",
      "\n",
      "Recall score for best estimator:\n",
      "0.142857142857\n"
     ]
    }
   ],
   "source": [
    "#keep same param_grid for now\n",
    "#create StratefiedShuffleSplit object\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "cross_validator = StratifiedShuffleSplit(y = labels_train, random_state = 0)\n",
    "\n",
    "param_grid = {'min_samples_split': [1, 2, 3, 4, 5, 6, 10, 15, 20, 25, 30],\n",
    "             'max_depth': [4, 5, 6, 7, 8]}\n",
    "\n",
    "#create grid_search object\n",
    "gridCV_object = grid_search.GridSearchCV(estimator = DecisionTreeClassifier(random_state=53),\n",
    "                                        param_grid = param_grid,\n",
    "                                        scoring = 'recall',\n",
    "                                        cv = cross_validator)\n",
    "\n",
    "#fit to the data to the new grid search\n",
    "gridCV_object.fit(features_train, labels_train)\n",
    "\n",
    "#what were the parameteres chosen from the grid?\n",
    "print \"Parameters chosen from the grid:\"\n",
    "pprint(gridCV_object.best_params_)\n",
    "\n",
    "#get best estimator\n",
    "print \"Best estimator:\"\n",
    "clf_recall = gridCV_object.best_estimator_\n",
    "\n",
    "#get the best parameters for the best estimator\n",
    "print \"The best parameters for the best estimator:\"\n",
    "pprint(clf_recall.get_params())\n",
    "\n",
    "#check the scores\n",
    "from sklearn.metrics import recall_score\n",
    "print \"\\nRecall score for default decision tree:\"\n",
    "predictions_1 = clf.predict(features_test)\n",
    "print recall_score(predictions_1, labels_test)\n",
    "\n",
    "#now for the grid search determined parameters:\n",
    "print \"\\nRecall score for best estimator:\"\n",
    "predictions_recall = clf_recall.predict(features_test)\n",
    "print recall_score(predictions_recall, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "The next step is to use all of this wonderful grid searching capability on the Gaussian Naive Bayes model. That will get me the best parameters.\n",
    "\n",
    "First, I look up what the possible parameters are for the GaussianNB. Of course, this will also require that I normalize the data and do the Principle Components analysis on the data before it goes to the model so I will also have to do some data preparation and build a pipeline. \n",
    "\n",
    "The Gaussian Naive Bayes model takes the parameters of--ok, well it doesn't really have any parameters to take. It just wants the normalized data and the principle components if you are doing that. So, we will skip the Gaussian for now and, following the tutorial, add in the pipeline for the decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy Score:\n",
      "0.772727272727\n",
      "\n",
      "Pipeline parameters:\n",
      "{'clf': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=53, splitter='best'),\n",
      " 'clf__class_weight': None,\n",
      " 'clf__criterion': 'gini',\n",
      " 'clf__max_depth': None,\n",
      " 'clf__max_features': None,\n",
      " 'clf__max_leaf_nodes': None,\n",
      " 'clf__min_samples_leaf': 1,\n",
      " 'clf__min_samples_split': 2,\n",
      " 'clf__min_weight_fraction_leaf': 0.0,\n",
      " 'clf__presort': False,\n",
      " 'clf__random_state': 53,\n",
      " 'clf__splitter': 'best',\n",
      " 'imp': Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0),\n",
      " 'imp__axis': 0,\n",
      " 'imp__copy': True,\n",
      " 'imp__missing_values': 'NaN',\n",
      " 'imp__strategy': 'median',\n",
      " 'imp__verbose': 0,\n",
      " 'pca': PCA(copy=True, n_components=None, whiten=False),\n",
      " 'pca__copy': True,\n",
      " 'pca__n_components': None,\n",
      " 'pca__whiten': False,\n",
      " 'std': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      " 'std__copy': True,\n",
      " 'std__with_mean': True,\n",
      " 'std__with_std': True,\n",
      " 'steps': [('imp',\n",
      "            Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)),\n",
      "           ('std', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "           ('pca', PCA(copy=True, n_components=None, whiten=False)),\n",
      "           ('clf',\n",
      "            DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=53, splitter='best'))]}\n",
      "\n",
      "\n",
      "Recall Score: 0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# imp = Imputer(missing_values='NaN', strategy='0')\n",
    "# features_train = imp.fit_transform(features_train)\n",
    "# features_test = imp.fit_transform(features_test)\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"Pipeline Accuracy Score:\"\n",
    "print pipeline.score(features_test, labels_test)\n",
    "\n",
    "print \"\\nPipeline parameters:\"\n",
    "pprint(pipeline.get_params())\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "print \"\\n\\nRecall Score:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "\n",
    "#print pipeline.recall_score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run the grid search with the pipeline put in as the estimator. The things we want to change in the pipeline will be put in through the grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('std', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, n_components=None, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=N...plit=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=53, splitter='best'))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'pca__n_components': [2, 3, 4, 5, 6, 7], 'clf__max_depth': [4, 5, 6, 7, 8], 'clf__min_samples_split': [1, 2, 3, 4, 5, 6, 10, 15, 20, 25, 30], 'imp__strategy': ['median', 'most_frequent']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'imp__strategy': ['median', 'most_frequent'], \n",
    "              'clf__min_samples_split': [1, 2, 3, 4, 5, 6, 10, 15, 20, 25, 30],\n",
    "              'clf__max_depth': [4, 5, 6, 7, 8],\n",
    "              'pca__n_components': [2,3,4,5,6,7]}\n",
    "\n",
    "#create the GridSearchCV object using param_grid\n",
    "gridCV_object = grid_search.GridSearchCV(estimator = pipeline, \n",
    "                                        param_grid = param_grid,\n",
    "                                        cv = 8)\n",
    "\n",
    "gridCV_object.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from the grid search:{'clf__max_depth': 6,\n",
      " 'clf__min_samples_split': 5,\n",
      " 'imp__strategy': 'median',\n",
      " 'pca__n_components': 3}\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print \"Best parameters from the grid search:\", pprint(gridCV_object.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pipeline_gridCV = gridCV_object.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Best estimator accuracy: 0.772727272727\n"
     ]
    }
   ],
   "source": [
    "print \"\\nBest estimator accuracy:\", clf_pipeline_gridCV.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can switch out the tree classifier for the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', RandomForestClassifier(random_state=53, class_weight = 'balanced'))\n",
    "    ])\n",
    "\n",
    "param_grid = {'imp__strategy':['median'],\n",
    "              'clf__min_sample_split': [1,5,10,15,20,25,30],\n",
    "              'clf__max_depth': [4,5,6,7,8],\n",
    "              'pca__n_components': [2,3,4,5,6,7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a grid search with the random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep same param_grid for now\n",
    "#create StratefiedShuffleSplit object\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "cross_validator = StratifiedShuffleSplit(y = labels_train, random_state = 0)\n",
    "\n",
    "param_grid = {'min_samples_split': [1, 2, 3, 4, 5, 6, 10, 15, 20, 25, 30],\n",
    "             'max_depth': [4, 5, 6, 7, 8]}\n",
    "\n",
    "#create grid_search object\n",
    "gridCV_object = grid_search.GridSearchCV(estimator = DecisionTreeClassifier(random_state=53),\n",
    "                                        param_grid = param_grid,\n",
    "                                        scoring = 'recall',\n",
    "                                        cv = cross_validator)\n",
    "\n",
    "#fit to the data to the new grid search\n",
    "gridCV_object.fit(features_train, labels_train)\n",
    "\n",
    "#what were the parameteres chosen from the grid?\n",
    "print \"Parameters chosen from the grid:\"\n",
    "pprint(gridCV_object.best_params_)\n",
    "\n",
    "#get best estimator\n",
    "print \"Best estimator:\"\n",
    "clf_recall = gridCV_object.best_estimator_\n",
    "\n",
    "#get the best parameters for the best estimator\n",
    "print \"The best parameters for the best estimator:\"\n",
    "pprint(clf_recall.get_params())\n",
    "\n",
    "#check the scores\n",
    "from sklearn.metrics import recall_score\n",
    "print \"\\nRecall score for default decision tree:\"\n",
    "predictions_1 = clf.predict(features_test)\n",
    "print recall_score(predictions_1, labels_test)\n",
    "\n",
    "#now for the grid search determined parameters:\n",
    "print \"\\nRecall score for best estimator:\"\n",
    "predictions_recall = clf_recall.predict(features_test)\n",
    "print recall_score(predictions_recall, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Tune precision and recall > 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize by subtracting mean and dividing by std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Create a minimum and maximum processor object\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "features_train = standard_scaler.fit_transform(features_train)\n",
    "features_test = standard_scaler.fit_transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to use the select k best method on the data and then see how it does with the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "COACH QUESTION: Where do I do the k-best thing? Can it be added to a pipeline below? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.61633\tPrecision: 0.21514\tRecall: 0.70900\tF1: 0.33011\tF2: 0.48592\n",
      "\tTotal predictions: 15000\tTrue positives: 1418\tFalse positives: 5173\tFalse negatives:  582\tTrue negatives: 7827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COACH QUESTION: Why doesn't the rbf kernel work? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf',C=100) \n",
    "# tried gamma=0.001, C=100.\n",
    "# kernel = 'linear', kernel='rbf'\n",
    "test_classifier(clf, my_dataset, features_list, folds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=7, whiten=False)), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA(n_components=7)), ('svm', svm.SVC(kernel='rbf'))]\n",
    "clf = Pipeline(estimators)\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Winner\n",
    "COACH QUESTION: So the Guassian Naive Bayes with the dimensions of the data set reduced to 8 through prinicple component analysis is the one that I got to break the 0.3 thresholds in Recall and Precision. I did it by just doing a manual search through the possible number of components. I have no idea which components were chosen and on what basis they worked, which 8 worked better than 9 or why 7 didn't make the 0.3 cut at all. I have no intuition for why any of this worked. And I don't know how to visualize it. Can I just submit this for the final project? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=8, whiten=False)), ('Gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.85053\tPrecision: 0.42568\tRecall: 0.34650\tF1: 0.38203\tF2: 0.35989\n",
      "\tTotal predictions: 15000\tTrue positives:  693\tFalse positives:  935\tFalse negatives: 1307\tTrue negatives: 12065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA(n_components=8)), ('Gaussian', GaussianNB())]\n",
    "clf = Pipeline(estimators)\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
