{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project restart: Vivek\n",
    "Import the modules, assign variables and define functions.\n",
    "\n",
    "This is the version that I am using since I got some advice from Vivek on the forum. He is really great and added a great customized function for getting the scoring function to work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "                                                \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "Defining functions that I will use for data import and prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = \"final_project_dataset.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_data(data):\n",
    "    '''This are the things I will do to import the data everytime, \n",
    "    regardless of what variables I make.'''\n",
    "    with open(data, \"r\") as data_file:\n",
    "        data_dict = pickle.load(data_file)\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.transpose()\n",
    "    df = df.drop('email_address', axis=1)\n",
    "    df = df.astype(float)\n",
    "    df = df.drop('TOTAL')\n",
    "    df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "    df = df.drop(\"loan_advances\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data1(data):\n",
    "    '''This are the things I will do to import the data everytime, \n",
    "    regardless of what variables I make.'''\n",
    "    with open(data, \"r\") as data_file:\n",
    "        data_dict1 = pickle.load(data_file)\n",
    "    return data_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = import_data1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = import_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels_new(df):\n",
    "    '''This is where the features and labels are extracted to use as arguments\n",
    "    for sklearn\\'s cross_validation function. It is also where I will do add\n",
    "    any new variables.'''\n",
    "    df['deferred_ratio'] = df['deferred_income']/(df['total_payments'] + 1)\n",
    "    df['pct_from_poi'] = df['from_poi_to_this_person']/(df['from_messages'] + 1)\n",
    "    df['pct_to_poi'] = df['from_this_person_to_poi']/(df['from_messages'] + 1)\n",
    "    df['to_from'] = df['pct_from_poi']*df['pct_from_poi']\n",
    "    features_list = list(df.columns)\n",
    "    features_list.remove('poi')\n",
    "    features = df[features_list]\n",
    "    labels = df['poi']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels_drop(df):\n",
    "    '''This is where the features and labels are extracted to use as arguments\n",
    "    for sklearn\\'s cross_validation function. It is also where I will do add\n",
    "    any new variables.\n",
    "    dropping director_fees, restricted_stock_preferred'''\n",
    "    df = df.drop('restricted_stock_deferred', axis=1)\n",
    "    df = df.drop('director_fees', axis=1)\n",
    "    features_list = list(df.columns)\n",
    "    features_list.remove('poi')\n",
    "    features = df[features_list]\n",
    "    labels = df['poi']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_labels(df):\n",
    "    '''This is where the features and labels are extracted to use as arguments\n",
    "    for sklearn\\'s cross_validation function. This function has no new features \n",
    "    added into the data set.'''\n",
    "    features_list = list(df.columns)\n",
    "    features_list.remove('poi')\n",
    "    features = df[features_list]\n",
    "    labels = df['poi']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features, labels = get_features_labels_new(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_test_split(features, labels):\n",
    "    '''This gets the train test split for the sklearn runs of the model'''\n",
    "    from sklearn import cross_validation\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    return features_train, features_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-211b5ce7ac05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = get_train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Functions\n",
    "The functions I will call to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code from vivek_29420285151271 to replace f1 as scoring criterion\n",
    "\n",
    "def precision_recall(labels,predictions):\n",
    "    ind_true_pos = [i for i in range(0,len(labels)) if (predictions[i]==1) & (labels[i]==1)]\n",
    "    ind_false_pos = [i for i in range(0,len(labels)) if ((predictions[i]==1) & (labels[i]==0))]\n",
    "    ind_false_neg = [i for i in range(0,len(labels)) if ((predictions[i]==0) & (labels[i]==1))]\n",
    "    ind_true_neg = [i for i in range(0,len(labels)) if ((predictions[i]==0) & (labels[i]==0))]\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    \n",
    "    \n",
    "    ind_labels = [i for i in range(0,len(labels)) if labels[i]==1]\n",
    "    \n",
    "    if len(ind_labels) !=0:\n",
    "        if float( len(ind_true_pos) + len(ind_false_pos))!=0:\n",
    "            precision = float(len(ind_true_pos))/float( len(ind_true_pos) + len(ind_false_pos))\n",
    "        if float( len(ind_true_pos) + len(ind_false_neg))!=0:\n",
    "            recall = float(len(ind_true_pos))/float( len(ind_true_pos) + len(ind_false_neg))\n",
    "        return precision, recall\n",
    "    else:\n",
    "        return -1,-1\n",
    "\n",
    "def custom_scorer(labels, predictions):\n",
    "    precision,recall = precision_recall(labels,predictions)\n",
    "    min_score = min(precision, recall)\n",
    "    return min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outcomes(grid_object):\n",
    "    '''Gets the print out of all the outcomes from the grid_search. It prints out the \n",
    "    best parameters found by the model and the outcomes of the test of the model on \n",
    "    the test set.'''\n",
    "    print \"Best parameters from the grid search:\", pprint(gridCV_object.best_params_)\n",
    "    clf_gridCV = gridCV_object.best_estimator_\n",
    "    print \"\\nBest Estimator Accuracy:\", clf_gridCV.score(features_test, labels_test)\n",
    "    clf_gridCV_pred = clf_gridCV.predict(features_test)\n",
    "    print \"\\nRecall Score:\", recall_score(labels_test, clf_gridCV_pred)\n",
    "    print \"\\nPrecision Score:\", precision_score(labels_test, clf_gridCV_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outcomes_whole_data_set(grid_object):\n",
    "    '''Gets the print out of all the outcomes from the grid_search. It prints out the \n",
    "    best parameters found by the model and the outcomes of the test of the model on \n",
    "    the test set, but using the whole data set rather than the train-test split.'''\n",
    "    print \"Best parameters from the grid search:\", pprint(gridCV_object.best_params_)\n",
    "    clf_gridCV = gridCV_object.best_estimator_\n",
    "    print \"\\nBest Estimator Accuracy:\", clf_gridCV.score(features_test, labels_test)\n",
    "    clf_gridCV_pred = clf_gridCV.predict(features)\n",
    "    print \"\\nRecall Score:\", recall_score(labels, clf_gridCV_pred)\n",
    "    print \"\\nPrecision Score:\", precision_score(labels, clf_gridCV_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis, feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e5ebe10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD7CAYAAACIYvgKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109641c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('poi')['restricted_stock_deferred'].agg(np.median).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e12ef90>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD7CAYAAACvzHniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e651590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('poi')['director_fees'].agg(np.median).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one thing I am going to do with this information is to remove the variables that are not associated in any way with the poi's. That might at least deal with the 1.0's problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from the grid search:{'clf__max_depth': 3, 'imp__strategy': 'mean', 'pca__n_components': 8}\n",
      " None\n",
      "\n",
      "Best Estimator Accuracy: 1.0\n",
      "\n",
      "Recall Score: 0.555555555556\n",
      "\n",
      "Precision Score: 0.909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Get custom scorer\n",
    "score = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "# Get data, here with the features unrealated to poi dropped.\n",
    "features, labels = get_features_labels_drop(df)\n",
    "\n",
    "# Get the test-train split\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels)\n",
    "\n",
    "# Build pipeline\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "# Build Grid\n",
    "x = [x for x in range(2,10)]\n",
    "d = [d for d in range(2,4)]\n",
    "param_grid = {'pca__n_components': x,\n",
    "              'clf__max_depth': d,\n",
    "              'imp__strategy':['most_frequent','median','mean']}\n",
    "\n",
    "# set model parameters to grid search object\n",
    "gridCV_object = GridSearchCV(estimator = Pipeline, \n",
    "                             param_grid = param_grid,\n",
    "                             scoring = score,\n",
    "                             cv = StratifiedShuffleSplit(labels, test_size=0.1,  n_iter=100))\n",
    "\n",
    "# train the model\n",
    "gridCV_object.fit(features, labels)\n",
    "\n",
    "# apply model to test data, print results\n",
    "get_outcomes_whole_data_set(gridCV_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Same model submitted to the grader: \n",
    "\n",
    "Start from begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "def import_data1(data):\n",
    "    '''This are the things I will do to import the data everytime, \n",
    "    regardless of what variables I make.'''\n",
    "    with open(data, \"r\") as data_file:\n",
    "        data_dict1 = pickle.load(data_file)\n",
    "    return data_dict1\n",
    "\n",
    "df1 = import_data1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#change to pandas data frame\n",
    "df1 = pd.DataFrame(df1)\n",
    "df1 = df1.transpose()\n",
    "df1 = df1.drop('email_address', axis=1)\n",
    "df1 = df1.astype(float)\n",
    "df1 = df1.drop('TOTAL')\n",
    "df1 = df1.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df1 = df1.drop(\"loan_advances\", axis=1)\n",
    "df1 = df1.drop('restricted_stock_deferred', axis=1)\n",
    "df1 = df1.drop('director_fees', axis=1)\n",
    "df1['deferred_ratio'] = df1['deferred_income']/(df['total_payments'] + 1)\n",
    "df1['pct_from_poi'] = df1['from_poi_to_this_person']/(df['from_messages'] + 1)\n",
    "df1['pct_to_poi'] = df1['from_this_person_to_poi']/(df['from_messages'] + 1)\n",
    "df1['to_from'] = df1['pct_from_poi']*df['pct_from_poi']\n",
    "\n",
    "features_list = list(df1.columns)\n",
    "features_list.remove('poi')\n",
    "features_list.insert(0, 'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change back to dictionary\n",
    "df1 = df1.transpose()\n",
    "df1 = df1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "And these are the results going through the test classifier:\n",
      "\n",
      "Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values='NaN', strategy='most_frequent',\n",
      "    verbose=0)), ('std', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, n_components=4, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max...plit=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=53, splitter='best'))])\n",
      "\tAccuracy: 0.82467\tPrecision: 0.19595\tRecall: 0.10150\tF1: 0.13373\tF2: 0.11233\n",
      "\tTotal predictions: 15000\tTrue positives:  203\tFalse positives:  833\tFalse negatives: 1797\tTrue negatives: 12167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "clf = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='most_frequent')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA(n_components=4)),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53, max_depth=2))\n",
    "    ])\n",
    "\n",
    "print \"\\n\\nAnd these are the results going through the test classifier:\\n\"\n",
    "test_classifier(clf, df1, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0bd0428ede8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get data, here with the features unrealated to poi dropped.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_labels_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get data, here with the features unrealated to poi dropped.\n",
    "features, labels, features_list = get_features_labels_drop(df)\n",
    "\n",
    "data_dict = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-30f7cd88b2df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "type(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-08f5fe1e968f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'poi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "features_list.insert(0, 'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6273ebe6c468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "And these are the results going through the test classifier:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7abe49f5cedb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\n\\nAnd these are the results going through the test classifier:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "clf = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='mean')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA(n_components=9)),\n",
    "        ('clf', DecisionTreeClassifier(max_depth=3, random_state = 53))\n",
    "    ])\n",
    "\n",
    "print \"\\n\\nAnd these are the results going through the test classifier:\\n\"\n",
    "test_classifier(clf, df1, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dcfbbbdf721b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'poi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict['poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "First attempt with the new scorer. Not sure whether this is the old or the new data set. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 8, 'imp__strategy': 'median', 'pca__n_components': 9}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.772727272727\n",
    "\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "\n",
    "Precision Score: 0.142857142857\n",
    "```\n",
    "This time I am doing it with the original data set for sure. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 5,\n",
    " 'imp__strategy': 'most_frequent',\n",
    " 'pca__n_components': 10}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "With the original data in the data set we seem to do a little better than with the new, created variables. Precision seems to be a lot better with the original, untreated data. \n",
    " \n",
    "I am running it one more time with \\_new data just to make sure that was the problem. \n",
    "```\n",
    "Best parameters from the grid search:{'clf__max_depth': 9, 'imp__strategy': 'median', 'pca__n_components': 4}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.818181818182\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "Precision Score: 0.2\n",
    "```\n",
    "Ok, that is not exactly the result we got before but it still shows the data with additional data to perform less well. \n",
    "\n",
    "Also, have to run Vivek's suggestion of limiting the depth of the trees to 2 or 3 or setting a minimum sample split because there is so little data. So here is one more time with the max depth set lower. That should not increase the preformance of the model (since our scoring features is selecting the model that performs the best) but it might provide some insight. Also, again following Vivek's suggestion, I will limit the principle component analysis to 10. \n",
    "```\n",
    "Best parameters from the grid search:{'clf__max_depth': 3, 'imp__strategy': 'most_frequent', 'pca__n_components': 3}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.75\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "Precision Score: 0.125\n",
    "```\n",
    "Yeah, not such hot performance but at least is makes more sense. \n",
    "\n",
    "Now I am going to see if the model can work better with the two variables that have no association with the dependent variable, the 'drop' data set. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 3, 'imp__strategy': 'most_frequent', 'pca__n_components': 6}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.977272727273\n",
    "\n",
    "Recall Score: 1.0\n",
    "\n",
    "Precision Score: 0.833333333333\n",
    "```\n",
    "Now, with that as a base line lets see if the Robust Scaler works better. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 3, 'imp__strategy': 'most_frequent', 'pca__n_components': 7}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.909090909091\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "Precision Score: 1.0\n",
    "```\n",
    "Ok, this is a lot worse. In fact, it is so much worse that I can't believe these results are correct. I must have changed something other than the just the scaler. \n",
    "\n",
    "These are the results with the two 0 poi variables dropped and the grid search run on the whole data set. \n",
    "```\n",
    "Best parameters from the grid search:{'clf__max_depth': 2, 'imp__strategy': 'most_frequent', 'pca__n_components': 8}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.909090909091\n",
    "\n",
    "Recall Score: 0.444444444444\n",
    "\n",
    "Precision Score: 0.888888888889\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with 1000, 10 and 100 iterations\n",
    "\n",
    "### 1000 iterations\n",
    "So the first outcome from the model is pretty good. It is StratifiedShuffleSplit with 1000 iterations. The outcome was really good but it took forever. \n",
    "\n",
    "```\n",
    "Best parameters from the grid search:{'clf__max_depth': 9, 'pca__n_components': 10}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.6\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "### 10 iterations\n",
    "This is great but I just can't use this for testing things out. It will take forever. So, I am going to try it with 10 iterations and see what happens. \n",
    "\n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 9, 'pca__n_components': 12}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.863636363636\n",
    "\n",
    "\n",
    "Recall Score: 0.4\n",
    "\n",
    "\n",
    "Precision Score: 0.4\n",
    "```\n",
    "### 100\n",
    "Now we get the same depth but 12 instead of 10 principle components. The scores have gone down though. It is worth trying it at a higher number of iterations. I am going to try 100. Here is the outcome: \n",
    "```\n",
    "Best Estimator Accuracy: 0.818181818182\n",
    "\n",
    "\n",
    "Recall Score: 0.4\n",
    "\n",
    "\n",
    "Precision Score: 0.285714285714\n",
    "```\n",
    "Ok, so 100 iterations is worse than either 1000 or 10 iterations. That is kind of distressing. It would be nice if the behavior of the model was 'monotonic', that is, the more of one thing you do the more of something you are looking for you get. I was thinking that 100 iterations could serve as a good way to explore possibilities and narrow the search space while reserving 1000 iteration runs to make the final cut. Now I am not quite sure what to do. \n",
    "\n",
    "And here is another thing. I just ran the model again with 1000 iterations with the single addition of the clf's criterion being 'gini' or 'entropy'. It came back with gini as the better criterion. And the model had performance that was just as good as before on the 1000 iterations. In fact, the three scores of interest--accuracy, precision and recall--were exactly the same. But it found a max depth of 7 instead of 9. \n",
    "```\n",
    "Best parameters from the grid search:{'clf__criterion': 'gini', 'clf__max_depth': 7, 'pca__n_components': 10}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.6\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "The reason that is so puzzling to me is that gini is the default scoring criterion for the model. So it was using gini before when it found the best preformance was at max depth of 9 instead of 7. How does that happen?\n",
    "\n",
    "### Adding variables\n",
    "\n",
    "In this iteration I try adding some new variables and the choice between the median and most_frequent imputation for the missing values. I also limited the search space for 'max_depth' and the number of components to 6-8 and 8-12 respectively. That may have been a mistake because I had found that the most effective max depth was 9. I don't know why I did that. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 7, 'imp__strategy': 'most_frequent', 'pca__n_components': 8}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "The results are strange in that adding more variables decreased the preformance, but I can't be sure that it wasn't because of my odd choice of cutting off the max_depth at 8 instead of 9. \n",
    "\n",
    "Also, I don't know why the max_depth is a useful parameter since the default is None. How could limiting the parameter improve preformance? \n",
    "\n",
    "## New Variables with modified parameter search space\n",
    "\n",
    "Just to satisfy my curiosity I am going to increase the max_depth parameter to 10 and raise the maximum number of principle components to 16 to account for the four newly added variables.\n",
    "\n",
    "#### Civil Libertarian Improvement\n",
    "\n",
    "So this turns out to have been a good idea. I have had a slight loss in recall but big gains in accuracy and precision. Given that I am a civil libertarian I personally feel this is an improvement. \n",
    "\n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 8, 'imp__strategy': 'most_frequent', 'pca__n_components': 8}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.909090909091\n",
    "\n",
    "\n",
    "Recall Score: 0.4\n",
    "\n",
    "\n",
    "Precision Score: 0.666666666667\n",
    "```\n",
    "Now I have one problem with these results in that the number of principle components chosen was at the bottom of the range I had specified. So now I have to face the possibility that there was better preforming model with a smaller dimensional principle component space that was over looked by the paramters to which I limited the grid search. So, as a double check, I am going to let the space searced go down. I am also going to keep the 'most_frequent' strategy and not search that space anymore. \n",
    "\n",
    "### Fewer dimensions: Insanity\n",
    "\n",
    "Ok, this is the kind of insane behavior that is driving me insane. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 8, 'pca__n_components': 7}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.863636363636\n",
    "\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "\n",
    "Precision Score: 0.333333333333\n",
    "```\n",
    "Now, all I did was specify 'most_frequent' as the method of imputation and offered it the choice of finding few dimensions in the principle component analysis. Everything else was the same. So how could the model get worse? It had the choice of keeping the model that had preformed better in the last specificaiton of the model, so how could it get worse? \n",
    "## Showdown\n",
    "Ok, I am just going to test everything. I am going to have a model of 200 different possible parameter configurations, but I am going to know once and for all what's what. Since I have never had entropy come up as the better scoring criterion I am going to leave that out but I am going to try everything else I have tried with the broades possible ranges. \n",
    "\n",
    "I am doing this essentially because I have to know once and for all whether more variables improve things or not. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 7, 'imp__strategy': 'most_frequent', 'pca__n_components': 8}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "So by expanding the grid search the model actually does worse. That is really distressing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Test\n",
    "So now I have been running into cases where I expand the search grid but end up with a less effective model. This is puzzling. It seems that if I have the models parameters set wider but still including the original model it should do at least as well as the original model. So, I am going to test the proposition and try to recreate the problem. \n",
    "\n",
    "First I will run the model that preformed the best above. \n",
    "\n",
    "Then I will run a model with a slightly expanded grid search. \n",
    "\n",
    "Then I will run a model with a much expanded grid search. \n",
    "\n",
    "### Larger Data Set-Original Settings\n",
    "So I tried it with the original grid search settings, with the choice between 'median' and most_frequent', principle components pared down to the range from 2 to 10 and the max depth set to the range from 6 to 9. The results were pretty good. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 8, 'imp__strategy': 'most_frequent', 'pca__n_components': 8}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.909090909091\n",
    "\n",
    "\n",
    "Recall Score: 0.4\n",
    "\n",
    "\n",
    "Precision Score: 0.666666666667\n",
    "```\n",
    "That is reassuring because it is the exact outcome from the model that I labeled the 'civil libertarian improvement' above. \n",
    "\n",
    "What was odd was when I gave it the exact settings that had preformed best in the broadest grid search with the smaller data set: depth 9/components 10, I got the error about something being 0. Then I changed the grid search to have lists for the components and depth parameters of 8,9 and 9,10 respectively so that model would run without objecting that it needed lists in the grid search parameters. The outcome is acceptable but the preformance has gone down since adding new variables. That is really weird. \n",
    "```\n",
    "\n",
    "Best parameters from the grid search:{'clf__max_depth': 8, 'imp__strategy': 'most_frequent', 'pca__n_components': 9}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.4\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "So maybe adding new variables that are simply restatements of the information in the old variables does not really help. Maybe it makes things worse by increasing dimensionality without adding genuinely new information, or at least not new enough information to justify the increase in the dimensionality of the search space. (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using functions; comparing new features, models\n",
    "So now I want to make use of the new functions I have defined above to do experiments with the data set, making small variations in the specifications of models to see what the effect of specific, individual changes are. Here is my list of functions: \n",
    "```\n",
    "features, labels = get_features_labels(df)\n",
    "\n",
    "features, labels = get_features_labels_new(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from the grid search:{'clf__max_depth': 9, 'pca__n_components': 8}\n",
      " None\n",
      "\n",
      "Best Estimator Accuracy: 1.0\n",
      "\n",
      "Recall Score: 1.0\n",
      "\n",
      "Precision Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "score = make_scorer(custom_scorer, greater_is_better=True)\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "x = [x for x in range(8,9)]\n",
    "d = [d for d in range(9,10)]\n",
    "param_grid = {'pca__n_components': x,\n",
    "              'clf__max_depth': d}\n",
    "\n",
    "gridCV_object = GridSearchCV(estimator = Pipeline, \n",
    "                             param_grid = param_grid,\n",
    "                             scoring = score,\n",
    "                             cv = StratifiedShuffleSplit(labels, test_size=0.1, n_iter=100))\n",
    "\n",
    "gridCV_object.fit(features, labels)\n",
    "\n",
    "# print all the outcomes of interest\n",
    "get_outcomes(gridCV_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is really interesting. I have run the stratified shuffle split with the entire data set rather than the 70-30 split. The idea is that the model takes in all the information available in the data set. That should increase preformance. I also kept scoring set to f1. But the outcome has been terrible. Now I am getting 1.0 for everything. \n",
    "\n",
    "UPDATE, I am running it again with the max depth search parameters set to a wider range as well as the principle components search. The outcome is still the same, with the scores all being 1.0.  \n",
    "\n",
    "UPDATE: I got it to work with the custom scorer, running the stratified shuffle split tester for only 100 iterations. It found a rather different model, particularly with the max depth being set at 4. But the recall score is way down. \n",
    "```\n",
    "Best parameters from the grid search:{'clf__max_depth': 4,\n",
    " 'imp__strategy': 'most_frequent',\n",
    " 'pca__n_components': 11}\n",
    " None\n",
    "\n",
    "Best Estimator Accuracy: 0.886363636364\n",
    "\n",
    "\n",
    "Recall Score: 0.2\n",
    "\n",
    "\n",
    "Precision Score: 0.5\n",
    "```\n",
    "On the grader we get: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is a block where I am going to store code that I might need later\n",
    "\n",
    "```\n",
    "              'imp__strategy':['most_frequent','median']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submitting to the Udacity Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)\n",
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df = df.drop(\"loan_advances\", axis=1)\n",
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')\n",
    "features = df[features_list]\n",
    "labels = df['poi']\n",
    "\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Imputer: median\n",
      "Normalize: StandardScaler\n",
      "PCA: dimensions unspecified\n",
      "\n",
      "Accuracy Score: 0.863636363636\n",
      "\n",
      "Recall: 0.6\n",
      "\n",
      "Precision: 0.428571428571\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"\"\"DecisionTreeClassifier\\nImputer: median\\nNormalize: StandardScaler\\nPCA: dimensions unspecified\"\"\"\n",
    "print \"\\nAccuracy Score:\", pipeline.score(features_test, labels_test)\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "\n",
    "print \"\\nRecall:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "print \"\\nPrecision:\", precision_score(labels_test, clf_pipeline_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra data prep to give to the grader. \n",
    "Put 'poi' at the top of the features_list and put the whole pandas data frame into a dictionary called 'data_dict'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>...</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>deferred_ratio</th>\n",
       "      <th>pct_from_poi</th>\n",
       "      <th>pct_to_poi</th>\n",
       "      <th>to_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1201773.074074</td>\n",
       "      <td>841602.526316</td>\n",
       "      <td>-581049.812500</td>\n",
       "      <td>89822.875000</td>\n",
       "      <td>2959559.257426</td>\n",
       "      <td>54192.010638</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>64.895349</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>746491.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>621892.823529</td>\n",
       "      <td>284087.542553</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>2.641806e+06</td>\n",
       "      <td>3352073.024000</td>\n",
       "      <td>-18.935722</td>\n",
       "      <td>1.062867</td>\n",
       "      <td>0.178236</td>\n",
       "      <td>4.803411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1441679.438330</td>\n",
       "      <td>1289322.626180</td>\n",
       "      <td>942076.402972</td>\n",
       "      <td>41112.700735</td>\n",
       "      <td>5499449.598994</td>\n",
       "      <td>46108.377454</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>86.979244</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>862917.421568</td>\n",
       "      <td>...</td>\n",
       "      <td>3845528.349509</td>\n",
       "      <td>177131.115377</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>9.524694e+06</td>\n",
       "      <td>6532883.097201</td>\n",
       "      <td>103.043649</td>\n",
       "      <td>1.927938</td>\n",
       "      <td>0.202476</td>\n",
       "      <td>16.932893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>-102500.000000</td>\n",
       "      <td>-3504386.000000</td>\n",
       "      <td>3285.000000</td>\n",
       "      <td>3285.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1787380.000000</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>-44093.000000</td>\n",
       "      <td>-696.308725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>425000.000000</td>\n",
       "      <td>79644.500000</td>\n",
       "      <td>-611209.250000</td>\n",
       "      <td>83674.500000</td>\n",
       "      <td>506765.000000</td>\n",
       "      <td>22479.000000</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>275000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-329825.000000</td>\n",
       "      <td>211802.000000</td>\n",
       "      <td>249.750000</td>\n",
       "      <td>541.250000</td>\n",
       "      <td>3.969340e+05</td>\n",
       "      <td>494136.000000</td>\n",
       "      <td>-0.676185</td>\n",
       "      <td>0.045432</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0.002124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>750000.000000</td>\n",
       "      <td>221063.500000</td>\n",
       "      <td>-151927.000000</td>\n",
       "      <td>106164.500000</td>\n",
       "      <td>1297049.000000</td>\n",
       "      <td>46547.500000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>422158.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-140264.000000</td>\n",
       "      <td>258741.000000</td>\n",
       "      <td>740.500000</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1.101393e+06</td>\n",
       "      <td>1095040.000000</td>\n",
       "      <td>-0.289940</td>\n",
       "      <td>0.373864</td>\n",
       "      <td>0.100531</td>\n",
       "      <td>0.139787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1200000.000000</td>\n",
       "      <td>867211.250000</td>\n",
       "      <td>-37926.000000</td>\n",
       "      <td>112815.000000</td>\n",
       "      <td>2542813.000000</td>\n",
       "      <td>78408.500000</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>831809.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-72419.000000</td>\n",
       "      <td>308606.500000</td>\n",
       "      <td>1888.250000</td>\n",
       "      <td>2634.750000</td>\n",
       "      <td>2.087530e+06</td>\n",
       "      <td>2606763.000000</td>\n",
       "      <td>-0.095255</td>\n",
       "      <td>1.131719</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>1.283187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8000000.000000</td>\n",
       "      <td>6426990.000000</td>\n",
       "      <td>-833.000000</td>\n",
       "      <td>137864.000000</td>\n",
       "      <td>34348384.000000</td>\n",
       "      <td>228763.000000</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>5145434.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15456290.000000</td>\n",
       "      <td>1111258.000000</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>1.035598e+08</td>\n",
       "      <td>49110078.000000</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count       81.000000          38.000000        48.000000      16.000000   \n",
       "mean   1201773.074074      841602.526316   -581049.812500   89822.875000   \n",
       "std    1441679.438330     1289322.626180    942076.402972   41112.700735   \n",
       "min      70000.000000     -102500.000000  -3504386.000000    3285.000000   \n",
       "25%     425000.000000       79644.500000   -611209.250000   83674.500000   \n",
       "50%     750000.000000      221063.500000   -151927.000000  106164.500000   \n",
       "75%    1200000.000000      867211.250000    -37926.000000  112815.000000   \n",
       "max    8000000.000000     6426990.000000      -833.000000  137864.000000   \n",
       "\n",
       "       exercised_stock_options       expenses  from_messages  \\\n",
       "count               101.000000      94.000000      86.000000   \n",
       "mean            2959559.257426   54192.010638     608.790698   \n",
       "std             5499449.598994   46108.377454    1841.033949   \n",
       "min                3285.000000     148.000000      12.000000   \n",
       "25%              506765.000000   22479.000000      22.750000   \n",
       "50%             1297049.000000   46547.500000      41.000000   \n",
       "75%             2542813.000000   78408.500000     145.500000   \n",
       "max            34348384.000000  228763.000000   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  long_term_incentive  \\\n",
       "count                86.000000                86.000000            65.000000   \n",
       "mean                 64.895349                41.232558        746491.200000   \n",
       "std                  86.979244               100.073111        862917.421568   \n",
       "min                   0.000000                 0.000000         69223.000000   \n",
       "25%                  10.000000                 1.000000        275000.000000   \n",
       "50%                  35.000000                 8.000000        422158.000000   \n",
       "75%                  72.250000                24.750000        831809.000000   \n",
       "max                 528.000000               609.000000       5145434.000000   \n",
       "\n",
       "          ...      restricted_stock_deferred          salary  \\\n",
       "count     ...                      17.000000       94.000000   \n",
       "mean      ...                  621892.823529   284087.542553   \n",
       "std       ...                 3845528.349509   177131.115377   \n",
       "min       ...                -1787380.000000      477.000000   \n",
       "25%       ...                 -329825.000000   211802.000000   \n",
       "50%       ...                 -140264.000000   258741.000000   \n",
       "75%       ...                  -72419.000000   308606.500000   \n",
       "max       ...                15456290.000000  1111258.000000   \n",
       "\n",
       "       shared_receipt_with_poi   to_messages  total_payments  \\\n",
       "count                86.000000     86.000000    1.230000e+02   \n",
       "mean               1176.465116   2073.860465    2.641806e+06   \n",
       "std                1178.317641   2582.700981    9.524694e+06   \n",
       "min                   2.000000     57.000000    1.480000e+02   \n",
       "25%                 249.750000    541.250000    3.969340e+05   \n",
       "50%                 740.500000   1211.000000    1.101393e+06   \n",
       "75%                1888.250000   2634.750000    2.087530e+06   \n",
       "max                5521.000000  15149.000000    1.035598e+08   \n",
       "\n",
       "       total_stock_value  deferred_ratio  pct_from_poi  pct_to_poi     to_from  \n",
       "count         125.000000       46.000000     86.000000   86.000000   86.000000  \n",
       "mean      3352073.024000      -18.935722      1.062867    0.178236    4.803411  \n",
       "std       6532883.097201      103.043649      1.927938    0.202476   16.932893  \n",
       "min        -44093.000000     -696.308725      0.000000    0.000000    0.000000  \n",
       "25%        494136.000000       -0.676185      0.045432    0.012417    0.002124  \n",
       "50%       1095040.000000       -0.289940      0.373864    0.100531    0.139787  \n",
       "75%       2606763.000000       -0.095255      1.131719    0.263720    1.283187  \n",
       "max      49110078.000000       -0.000312     11.000000    0.944444  121.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('restricted_stock_deferred', axis=1)\n",
    "df = df.drop('director_fees', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features_list[0] = 'poi'\n",
    "df_1 = df.transpose()\n",
    "data_dict = df_1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index does not support mutable operations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0ad278e0a614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'poi'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelreinhard/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index does not support mutable operations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index does not support mutable operations"
     ]
    }
   ],
   "source": [
    "features_list[0] = 'poi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a72506e3d2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deferred_ratio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "features_list.remove('deferred_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = features_list.insert(0,'poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
