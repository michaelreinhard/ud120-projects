{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson 12: PCA**\n",
    "\n",
    "The first 2/3s of the lesson is conceptual and really good. \n",
    "\n",
    "The big take away is that the principle component is the direction of maximal variance in the data. Like a lot of things in PCA, it sounds really complicated in English but communicated in the form of a picture it is really obvious. \n",
    "\n",
    "The principle components are also the directions that minimize the information loss when the data is reduced to them. \n",
    "\n",
    "Maximizing the variance minimizes the distance from the old points to the new transformed points. Thus, we are minimizing the information loss. \n",
    "\n",
    "So, PCA is an algorithm for feature selection. The great thing is that PCA can be done automatically, where the algorithm can take all features, no matter how many features there are, and come up with the principle components in the data without any human intervention. But, you don't know what the compentnets mean. \n",
    "\n",
    "PCA is a systematized way to transform input features into principle compenents. You then projecdt the actual data down into those principle compenents. \n",
    "\n",
    "All the PCs are orthogonal to each other. \n",
    "\n",
    "Now we start looking at real data using the data stored in \"ud120-projects/final_project/\"\n",
    "\n",
    "The main sklearn function we need is the [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) module. \n",
    "\n",
    "Now I she is going to explain the code *finance_pca.py* that is included in the \n",
    "The basic approach is to import the module, create the analyzer, fit it to the data, and return the re-fitted data in a pca object. We see this in the body of the do_PCA() function that is defined in the code: \n",
    "```\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)  # only fit, not transformed\n",
    "return pca\n",
    "```\n",
    "Then we get information out of the principle components analysis. \n",
    "\n",
    "There are several methods that access the data in a principle components analysis. \n",
    "```\n",
    "pca.explained_variance_ratio_\n",
    "first_pc = pca.components_[0]\n",
    "second_pc = pca.components_[1]\n",
    "```\n",
    "\n",
    "The explained variance ratio is where the eigen values live. \n",
    "\n",
    "The components is a python list. This is the directional information giving you the direction of the data, the direction it is transformed by to get the new axes. \n",
    "\n",
    "Then we want to make a graph showing the new data. We have to create a new data set of the transformed data that we can use to plot. Remember, we have only fit the data, we have not transformed it. \n",
    "```\n",
    "transformed_data = pca.transform(data)\n",
    "```\n",
    "Once we have the transformed data we can plot it against the original data and see how each principle component captures some of the variation in the data. \n",
    "```\n",
    "for ii, jj in zip(tranformed_data, data):\n",
    "    plt.scatter( first_pc[0]*ii[0], first_pc[1]*ii[0], color=\"r\"\n",
    "    plt.scatter( second_pc[0]*ii[1], second_pc[1]*ii[1], color=\"c\"\n",
    "    plt.scatter( jj[0], jj[1], color=\"b\"\n",
    "```\n",
    "So, in the for loop we create a new data set that combines the principle components and the original data. Then we somehow plot the components and the data together. \n",
    "\n",
    "The r is going to be the first principle components times the data, the cyan will be the second principle component times the data and the blue is going to be the original data. \n",
    "\n",
    "Finally, we will add some labels. \n",
    "```\n",
    "plt.xlabel(\"bonus\")\n",
    "plt.ylabel(\"long-term incentive\")\n",
    "plt.show()\n",
    "```\n",
    "Now, in presenting the analysis the first thing she does is print out the eigen values. \n",
    "```\n",
    "python finance_pca.py\n",
    "```\n",
    "This produces a 0.9 and a 0.09 number for the two components. As usual, the first principle component summarizes about ten times as much as the second principle component does. The print of out the numbers comes from the *pca.explained_variance_ratio_* statement in the code. \n",
    "\n",
    "Then you get a really cool scatter plot. You get the compact red and cyan points in a compact and almost orthoganal arrangement and the blue dots representing the original data in a much more spread out pattern. The two principle components are not perfectly orthogonal because they are of vastly different scales. \n",
    "\n",
    "*When do you use PCA?*\n",
    "\n",
    "Find latent features: find the bigshots at enron\n",
    "Dimensionality reduction\n",
    "    --visualize high dimensional data\n",
    "    --reduce noise\n",
    "    --make other algorithms run better\n",
    "\n",
    "*PCA for Facial Recognition*\n",
    "\n",
    "Eigen Faces: applying PCA to pictures of people. If you take all the pixels in people's faces and reduce them to the PCs, you can reconstruct the visual images using only the priciple components, thus, producing \"Eigen Faces\". \n",
    "\n",
    "You apply the PCA analysis to pictures of people and then let a SVM to identify people. \n",
    "\n",
    "There are tons of input features. Each pixel is an input. But there are only a few underlying big differences, where are the eyes, how long is the nose? \n",
    "\n",
    "So, the mini-project is to go through the Eigen Faces code and get it to work. I think I may postpone the mini-project on this lesson to get going on the Enron project sooner. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sklearn.datasets.lfw:Downloading LFW metadata: http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt\n",
      "WARNING:sklearn.datasets.lfw:Downloading LFW metadata: http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt\n",
      "WARNING:sklearn.datasets.lfw:Downloading LFW metadata: http://vis-www.cs.umass.edu/lfw/pairs.txt\n",
      "WARNING:sklearn.datasets.lfw:Downloading LFW data (~200MB): http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz\n"
     ]
    }
   ],
   "source": [
    "# %load eigenfaces.py\n",
    "\"\"\"\n",
    "===================================================\n",
    "Faces recognition example using eigenfaces and SVMs\n",
    "===================================================\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print __doc__\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly (as relative pixel\n",
    "# position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_classes: %d\" % n_classes\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 150\n",
    "\n",
    "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "t0 = time()\n",
    "param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Best estimator found by grid search:\"\n",
    "print clf.best_estimator_\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print \"Predicting the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names=target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                         for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
