{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final project restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "                                                \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tester import test_classifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)\n",
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df = df.drop(\"loan_advances\", axis=1)\n",
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')\n",
    "features = df[features_list]\n",
    "labels = df['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Pipeline: median imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Imputer: median\n",
      "Normalize: StandardScaler\n",
      "PCA: dimensions unspecified\n",
      "\n",
      "Accuracy Score: 0.863636363636\n",
      "\n",
      "Recall: 0.6\n",
      "\n",
      "Precision: 0.428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"\"\"DecisionTreeClassifier\\nImputer: median\\nNormalize: StandardScaler\\nPCA: dimensions unspecified\"\"\"\n",
    "print \"\\nAccuracy Score:\", pipeline.score(features_test, labels_test)\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "print \"\\nRecall:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "print \"\\nPrecision:\", precision_score(labels_test, clf_pipeline_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature-Data Reimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)\n",
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df = df.drop(\"loan_advances\", axis=1)\n",
    "#new feature\n",
    "df['deferred_ratio'] = df['deferred_income']/(df['total_payments'] + 1)\n",
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')\n",
    "features = df[features_list]\n",
    "labels = df['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Imputer: median\n",
      "Normalize: StandardScaler\n",
      "PCA: dimensions unspecified\n",
      "\n",
      "Accuracy Score: 0.795454545455\n",
      "\n",
      "Recall: 0.4\n",
      "\n",
      "Precision: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"\"\"DecisionTreeClassifier\\nImputer: median\\nNormalize: StandardScaler\\nPCA: dimensions unspecified\"\"\"\n",
    "print \"\\nAccuracy Score:\", pipeline.score(features_test, labels_test)\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "print \"\\nRecall:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "print \"\\nPrecision:\", precision_score(labels_test, clf_pipeline_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it is the new variable that causes the problem. I will try to convince myself of this by removing the new variable and trying it again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)\n",
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df = df.drop(\"loan_advances\", axis=1)\n",
    "#new feature\n",
    "# df['deferred_ratio'] = df['deferred_income']/(df['total_payments'] + 1)\n",
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')\n",
    "features = df[features_list]\n",
    "labels = df['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Imputer: median\n",
      "Normalize: StandardScaler\n",
      "PCA: dimensions unspecified\n",
      "\n",
      "Accuracy Score: 0.863636363636\n",
      "\n",
      "Recall: 0.6\n",
      "\n",
      "Precision: 0.428571428571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"\"\"DecisionTreeClassifier\\nImputer: median\\nNormalize: StandardScaler\\nPCA: dimensions unspecified\"\"\"\n",
    "print \"\\nAccuracy Score:\", pipeline.score(features_test, labels_test)\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "print \"\\nRecall:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "print \"\\nPrecision:\", precision_score(labels_test, clf_pipeline_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now I can get the thing to work. The best thing so far is using pca with no actual reduction in the number of dimensions and no new features added. Now I am going to try to submit that to the udacity grader. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Submitting to the Udacity Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df = pd.DataFrame(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', axis=1)\n",
    "df = df.astype(float)\n",
    "df = df.drop('TOTAL')\n",
    "df = df.drop(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "df = df.drop(\"loan_advances\", axis=1)\n",
    "features_list = list(df.columns)\n",
    "features_list.remove('poi')\n",
    "features = df[features_list]\n",
    "labels = df['poi']\n",
    "\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Imputer: median\n",
      "Normalize: StandardScaler\n",
      "PCA: dimensions unspecified\n",
      "\n",
      "Accuracy Score: 0.863636363636\n",
      "\n",
      "Recall: 0.6\n",
      "\n",
      "Precision: 0.428571428571\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "Pipeline = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline.fit(features_train, labels_train)\n",
    "\n",
    "print \"\"\"DecisionTreeClassifier\\nImputer: median\\nNormalize: StandardScaler\\nPCA: dimensions unspecified\"\"\"\n",
    "print \"\\nAccuracy Score:\", pipeline.score(features_test, labels_test)\n",
    "\n",
    "clf_pipeline_pred = pipeline.predict(features_test)\n",
    "print \"\\nRecall:\", recall_score(labels_test, clf_pipeline_pred)\n",
    "print \"\\nPrecision:\", precision_score(labels_test, clf_pipeline_pred)\n",
    "\n",
    "\n",
    "# x = [x for x in range(2,19)]\n",
    "# d = [d for d in range(2,10)]\n",
    "# param_grid = {'pca__n_components': x,\n",
    "#               'clf__max_depth': d}\n",
    "\n",
    "# gridCV_object = GridSearchCV(estimator = Pipeline, \n",
    "#                              param_grid = param_grid)\n",
    "\n",
    "# gridCV_object.fit(features_train, labels_train)\n",
    "\n",
    "# print \"Best parameters from the grid search:\", pprint(gridCV_object.best_params_)\n",
    "\n",
    "# clf_gridCV = gridCV_object.best_estimator_\n",
    "\n",
    "# print \"\\nBest Estimator Accuracy:\", clf_gridCV.score(features_test, labels_test)\n",
    "\n",
    "# clf_gridCV_pred = clf_gridCV.predict(features_test)\n",
    "\n",
    "# print \"\\n\\nRecall Score:\", recall_score(labels_test, clf_gridCV_pred)\n",
    "# print \"\\n\\nPrecision Score:\", precision_score(labels_test, clf_gridCV_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra data prep to give to the grader. \n",
    "Put 'poi' at the top of the features_list and put the whole pandas data frame into a dictionary called 'data_dict'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list[0] = 'poi'\n",
    "df_1 = df.transpose()\n",
    "data_dict = df_1.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Same model submitted to the grader: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "And these are the results going through the test classifier:\n",
      "\n",
      "Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('std', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, n_components=None, whiten=False)), ('clf', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=N...plit=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=53, splitter='best'))])\n",
      "\tAccuracy: 0.79173\tPrecision: 0.27005\tRecall: 0.33000\tF1: 0.29703\tF2: 0.31597\n",
      "\tTotal predictions: 15000\tTrue positives:  660\tFalse positives: 1784\tFalse negatives: 1340\tTrue negatives: 11216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "clf = Pipeline([\n",
    "        ('imp', Imputer(missing_values='NaN', strategy='median')),\n",
    "        ('std', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier(random_state = 53))\n",
    "    ])\n",
    "\n",
    "print \"\\n\\nAnd these are the results going through the test classifier:\\n\"\n",
    "test_classifier(clf, data_dict, features_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
