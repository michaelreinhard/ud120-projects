{
 "metadata": {
  "name": "",
  "signature": "sha256:af64558bb74c8d82df107906cdc21da26f04ab3047dd4b4541d788532cc3f7c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Lesson 3: Decision Trees**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the version of the notebook that I copied to the decision_tree directory in the cloned respository, \"ud120-projects\". I am still not sure how to save this in the repository so that the code updates when I update it locally. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "clf = tree.DecisionTreeClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are asked to calculate the entropy of a node. The formula for entropy is: $$\\Sigma {p_ilog_2(p_i)}$$ where p is the proportion of cases with a given label in a particular class. \n",
      "\n",
      "And we have 2 out of 4 of the labels in a given class, so $p_i = 0.5$. Now all we have to do is multiply 0.5 times the $log_2$ of 0.5."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "0.5*math.log(0.5,2) + 0.5*math.log(0.5,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "-1.0"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But the entropy should be bound between 0 and 1? The correct answer is 1, but why? Turns out I had the forumla wrong. It is $-p_i$ for the first term, $$\\Sigma {-p_ilog_2(p_i)}$$ So the calculation is: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-0.5*math.log(0.5,2) + -0.5*math.log(0.5,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have to do a specific problem for quiz 5: Information Gain Calculation. Here is the problem: $$-\\frac{2}{3}\\log_2(\\frac{2}{3})-\\frac{1}{3}\\log_2(\\frac{1}{3})$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-(0.67)*math.log(0.67, 2)-(0.33)*math.log(0.33, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.9149263727797274"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have to calculate the entropy in the child branches. Since one of the child categories has only one observation in it the entropy of that branch is 0 times the weight of that branch, 1/4. So that branch is 0. \n",
      "\n",
      "The other branch has 3/4 of the cases, so it is 3/4*0.9149263727797274. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(3.0/4.0)*(-(0.67)*math.log(0.67, 2)-(0.33)*math.log(0.33, 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0.6861947795847956"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, what is the information gain? The information gain is the entropy we started with minus the entropy we ended up with. The parent has an entropy of 1.0, recall, because there was maximum confusion. So it is 1 minus the entropy of the child branches, 0.6861947795847956, or: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1 - 0.6861947795847956"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.3138052204152044"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So if we split on the 'grade' (steep versus flat) we gain 0.314 in information. \n",
      "\n",
      "Now we want to calculate gain from splitting on the bumpiness. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-0.5*math.log(0.5,2)-(0.5)*math.log(0.5,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ".5*1+0.5*1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So what is the entropy of the bumpy train, where we have one two cases and two labels represented? $p_i$ is 0.5 for both labels so, "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-0.5*math.log(0.5,2)-0.5*math.log(0.5,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have to evaluate the information gain on splitting on speed limit. There are two values to speed limit and the two values line up perfectly with the two possible values for the labels. So, all the cases that have 1 on the speed limit (a speed limit exists) have the same value, slow, on speed, and all the cases that have 0 on the speed limit (there is no speed limit) have the same value, fast, on the label. So it seems like knowing whether there is a speed limit tells us a lot. In fact, in this data set, knowing the value of speed limit fully determines the value of interest, the label, for speed: slow or fast. \n",
      "\n",
      "So, intuitively, there should be a 100% information gain. \n",
      "\n",
      "(By the way, this seems a lot like the idea of degrees of freedom. Is there some formal relationship?)\n",
      "\n",
      "So, to test this intuition, I will go through the entropy calculations and subtract the end state entropy from the begining state entropy. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-1.0*math.log(1,2)-(1)*math.log(1,2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "-0.0"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Going to the sklearn documentation we see that the spliting function that the algorithm defaults to is something called the 'gini' function. You can change the criteria with the argument criterion='gini'. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Bias-Variance Trade-off**\n",
      "\n",
      "Bias is the degree to which a model is insensitive to the data. Variance, the opposing quality, is the degree to which a model is sensitive to the data. A model with too much bias does not take into account local conditions or new data enough. It persists in making decisions that may be appropriate to the environment it is optimized to deal with, but which are inefficient under current conditions. The problem with the high variance model is that it over-reacts to the data and so, when it sees new data, has \"nothing to default to\". \n",
      "\n",
      "Sebastian's explanation of what goes wrong when a model has too much variance is not entirely clear to me, but it seems that over-reacting to the data could mean changing your decisions too much, going from one extreme to another, or finding yourself unable to make a decision at all. A high variance model can only deal with situations it has seen before, otherwise it has no default to go to. The high bias model is one that is stuck on its default no matter what data it encounters.   \n",
      "\n",
      "We want a model that can generalize but does not over react to the data. \n",
      "\n",
      "I think I will write something about decision making and Churchill. His discussion of decision making in the war cabinet and particularly his objections to having 'unharnessed' ministers with nothing to do but engage in that 'exalted brooding' characteristic of committees made up of those with no operational responsibilities, seems to be a good illustration of what the bias-variance trade-off is getting at. \n",
      "\n",
      "Big problem with decision trees is that they are prone to over fitting, which I suppose is an example of having too much variance and not enough bias. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Mini-Project: Decision Trees*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /Users/michaelreinhard/nano/machineLearning/ud120-projects/decision_tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/michaelreinhard/nano/machineLearning/ud120-projects/decision_tree\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Update*\n",
      "\n",
      "After going back and looking at the course files I found the directions to the udacity repository for this course and the directions for cloning a repository [here](https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository). Now the respository is cloned and in my machineLearning directory. I also used the git init command and the git add \\*.ipynb to get make my ipython notebooks part of a git respository, though I am still not entirely sure how this works. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**The email_preprocess.py Script**\n",
      "\n",
      "I have just checked to see that the email_preprocess.py file is set to take the words from the top ten percentiles of the emails. I have also gotten rid of the .pyc file (which I should make part of the notebook) and I am going to run the reload commands. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will run the preprocessing "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "decision_tree.ipynb  dt_author_id.py\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run dt_author_id.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That only took a few seconds to run, so now the data should be ready. We see we have almost 8,000 emails from both parties. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dt_author_id.py script should have run the email_preprocess.py script and sure enough the .pyc file is there, indicating that the byte file has been created. Now I check to see how many words have been retained in the data set. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(features_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "3785"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, that is good. We have the correct number of variables in the data set. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we do the analysis as expected. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
      "clf.fit(features_train, labels_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
        "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
        "            min_density=None, min_samples_leaf=1, min_samples_split=40,\n",
        "            random_state=None, splitter='best')"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = clf.predict(features_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import accuracy_score\n",
      "accuracy = accuracy_score(pred, labels_test)\n",
      "print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.977246871445\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are asked to get the number of features in the data, or, in other words, the number of columns in the data set. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(features_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "3785"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we come to the question I could not get to work the first time around. \n",
      "\n",
      "The challenge is to see what is the effect on the accuracy of the model of using less data. Up till now we have been using the frequencies of words from the top ten percent of words occuring in the data set. \n",
      "\n",
      "Now we go into the pre-processing code and change the value of the selector from the /tools/email_preprocess.py file. The function is \n",
      "```\n",
      "selector = SelectPercentile(f_classif, percentile=10)\n",
      "```\n",
      "Once we have done that we will run the dt_author_id.py script, which  prepares the data for the decision tree model and presumably calls the email_process.py script at some point. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I have gotten it to run correctly by restarting the ipython notebook and kernel but that seems a bit cumbersome to do on a regular basis. So, I have gotten a suggestion from the Discussion boards, this code: \n",
      "```\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "```\n",
      "This should force the notebook to reload all the dependencies and rerun the emails_preprocess.py script every time I call the dt_author_id.py script. I am going to go back and change the emails_preprocess.py script in the vim editor and then come back and try this again with the percentile set to 1 instead of 10. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, now I have changed the script to percentile = 1 and deleted the .pyc file. Now I am going to set the auto reload code and see if it has any effect. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we rerun the code for the prepping the data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run dt_author_id.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no. of Chris training emails: 7936\n",
        "no. of Sara training emails: 7884\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I am going to run the features_train[0] to see how many words are in the data set. I am expecting to see some 3 hundreds of words rather than something over 3,000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(features_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "379"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, it worked! Here is all the code in one place: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%run dt_author_id.py\n",
      "len(features_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n",
        "no. of Chris training emails:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7936\n",
        "no. of Sara training emails: 7884\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "379"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that I have it working I am going to run the analysis again and answer the quiz question, does reducing the number of words in the data set reduce the accuracy and by how much? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
      "clf.fit(features_train, labels_train)\n",
      "pred = clf.predict(features_test)\n",
      "from sklearn.metrics import accuracy_score\n",
      "accuracy = accuracy_score(pred, labels_test)\n",
      "print accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.966439135381\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wow, the whole thing ran really fast and the accuracy is only down one percent. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I am going to put the emails_preprocess.py file back right and get rid of the .pyc file for future use by other programs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%rm ../tools/email_preprocess.pyc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/michaelreinhard/nano/machineLearning/ud120-projects\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd tools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/michaelreinhard/nano/machineLearning/ud120-projects/tools\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "email_authors.pkl          python2_lesson06_keys.pkl\r\n",
        "email_preprocess.py        python2_lesson13_keys.pkl\r\n",
        "feature_format.py          python2_lesson14_keys.pkl\r\n",
        "feature_format.pyc         startup.py\r\n",
        "parse_out_email_text.py    word_data.pkl\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, so that got rid of it. Now I just go back and change the file and confirm the changes by re-running the data prep script. First, get back into the home directory for this script."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../decision_tree/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/michaelreinhard/nano/machineLearning/ud120-projects/decision_tree\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%run dt_author_id.py\n",
      "len(features_train[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n",
        "no. of Chris training emails:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7936\n",
        "no. of Sara training emails: 7884\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "3785"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}